{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e32f8009-c317-49db-bf52-eb17ca153532",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Run data pipeline\n",
    "Returns an aggegrated df to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the file: 309857\n"
     ]
    }
   ],
   "source": [
    "#import dataframe\n",
    "df = pd.read_parquet('/home/joelva/code/pgt-group-3/data/processed/10_sec_processed/HECTORdataAggregated_20240615_1030.parquet')\n",
    "\n",
    "# Print the number of rows\n",
    "print(f\"Number of rows in the file: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'MotorJoules', 'ActualSpeed', 'NetWeight', 'DistanceKM',\n",
       "       'StopOnOff', 'ThrottlePerc', 'MotorUseCurrent', 'CompOnOff',\n",
       "       'FC1Current', 'FC2Current', 'FC3Current', 'MotorTemp', 'TotalFCPower',\n",
       "       'FC1AirFlow', 'FC3AirFlow', 'FC2AirFlow', 'BatTotalCurrent',\n",
       "       'BattOutputPower', 'MotorTorque', 'FC1Cool', 'FC2Cool', 'FC3Cool',\n",
       "       'TotalDistance', 'CompPower', 'FC3Volt', 'FC1Volt', 'FC2Volt',\n",
       "       'BatMaxV', 'BatTotalVoltage', 'BatMinV', 'HVACDraw', 'H2Weight',\n",
       "       'H2Press', 'BrakePerc', 'Signal', 'Is_Wednesday', 'BatSOC', 'Is_Friday',\n",
       "       'H2Temp', 'Is_Sunday', 'AirTemp', 'Is_Saturday', 'Is_Thursday',\n",
       "       'Is_Monday', 'Is_Tuesday', 'TotalPowerDraw', 'MotorRPM', 'TotalAxle',\n",
       "       'H2Perc', 'AltChange', 'SpeedChange'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum time of day: 04:00:09.700000\n",
      "Maximum time of day: 12:59:59.990000\n",
      "                  datetime  MotorJoules  ActualSpeed  NetWeight  DistanceKM  \\\n",
      "24 2022-08-01 04:08:19.880   124208.750    10.250625      900.0    0.013397   \n",
      "25 2022-08-01 04:08:29.870   332999.425    17.381875      800.0    0.019182   \n",
      "26 2022-08-01 04:08:39.850   133732.000     8.198750      900.0    0.045789   \n",
      "27 2022-08-01 04:08:49.860  1002175.775    25.243750     1100.0    0.035038   \n",
      "28 2022-08-01 04:08:59.850   716360.525    36.750000      900.0    0.101447   \n",
      "\n",
      "    StopOnOff  ThrottlePerc  MotorUseCurrent  CompOnOff  FC1Current  ...  \\\n",
      "24        1.0         252.6          190.575        0.0     -0.4075  ...   \n",
      "25        1.0         344.9          513.300        0.0     -0.4200  ...   \n",
      "26        1.0         267.3          206.475        0.0     -0.3900  ...   \n",
      "27        1.0         539.3         1569.875        0.0     -0.3675  ...   \n",
      "28        1.0         300.9         1118.450        0.0     -0.3825  ...   \n",
      "\n",
      "    Is_Saturday  Is_Thursday  Is_Monday  Is_Tuesday  TotalPowerDraw  MotorRPM  \\\n",
      "24            0            0          1           0      12420.8750    58.575   \n",
      "25            0            0          1           0      33299.9425    99.325   \n",
      "26            0            0          1           0      13373.2000    46.850   \n",
      "27            0            0          1           0     100217.5775   144.250   \n",
      "28            0            0          1           0      71636.0525   210.000   \n",
      "\n",
      "    TotalAxle  H2Perc  AltChange  SpeedChange  \n",
      "24    17900.0  41.925      0.165     3.176250  \n",
      "25    17800.0  41.800     -1.810     7.131250  \n",
      "26    17900.0  41.850     -1.780    -9.183125  \n",
      "27    18100.0  41.950     -1.275    17.045000  \n",
      "28    17900.0  41.700     -0.205    11.506250  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "#Check start and end time of days in df\n",
    "\n",
    "# Extract the time component from the 'datetime' column\n",
    "df['time'] = df['datetime'].dt.time\n",
    "\n",
    "# Find the minimum and maximum time\n",
    "min_time = df['time'].min()\n",
    "max_time = df['time'].max()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Minimum time of day: {min_time}\")\n",
    "print(f\"Maximum time of day: {max_time}\")\n",
    "\n",
    "# Optional: If you want to remove the 'time' column after finding the min and max\n",
    "df = df.drop(columns=['time'])\n",
    "\n",
    "# Output for verification\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309857"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NaN values: 0\n",
      "Columns with NaN values: []\n"
     ]
    }
   ],
   "source": [
    "# Count rows with NaN values\n",
    "rows_with_nans = df.isna().any(axis=1).sum()\n",
    "\n",
    "# Identify columns with NaN values\n",
    "columns_with_nans = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "print(f'Number of rows with NaN values: {rows_with_nans}')\n",
    "print(f'Columns with NaN values: {columns_with_nans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop remaining NANs\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       datetime  StopOnOff  ThrottlePerc  CompOnOff  \\\n",
      "24      2022-08-01 04:08:19.880        1.0         252.6        0.0   \n",
      "25      2022-08-01 04:08:29.870        1.0         344.9        0.0   \n",
      "26      2022-08-01 04:08:39.850        1.0         267.3        0.0   \n",
      "27      2022-08-01 04:08:49.860        1.0         539.3        0.0   \n",
      "28      2022-08-01 04:08:59.850        1.0         300.9        0.0   \n",
      "...                         ...        ...           ...        ...   \n",
      "1086231 2023-08-01 11:15:59.950        1.0         336.8        0.0   \n",
      "1086232 2023-08-01 11:16:09.940        1.0         364.0        0.0   \n",
      "1086233 2023-08-01 11:16:19.930        1.0         253.2        0.0   \n",
      "1086234 2023-08-01 11:16:29.880        1.0         147.2        0.0   \n",
      "1086235 2023-08-01 11:16:39.830        1.0          63.7        0.0   \n",
      "\n",
      "         TotalFCPower  FC1AirFlow  CompPower  FC3Volt  BatTotalVoltage  \\\n",
      "24           -0.08300         0.0        0.0      0.1          652.200   \n",
      "25           -0.09350         0.0        0.0      0.1          648.925   \n",
      "26           -0.08225         0.0        0.0      0.1          650.975   \n",
      "27           -0.08000         0.0        0.0      0.1          638.775   \n",
      "28           -0.07350         0.0        0.0      0.1          642.050   \n",
      "...               ...         ...        ...      ...              ...   \n",
      "1086231       0.40925         0.0        0.0      0.1          570.075   \n",
      "1086232       0.40975         0.0        0.0      0.1          572.250   \n",
      "1086233       0.41375         0.0        0.0      0.1          575.375   \n",
      "1086234       0.41625         0.0        0.0      0.1          573.700   \n",
      "1086235       0.40450         0.0        0.0      0.1          574.000   \n",
      "\n",
      "          BatMinV  ...  Signal  BatSOC  H2Temp  AirTemp  H2Perc  ActualSpeed  \\\n",
      "24       4115.650  ...     0.0  100.00  23.000     20.6  41.925    10.250625   \n",
      "25       4096.500  ...     0.0  100.00  23.000     20.6  41.800    17.381875   \n",
      "26       4104.050  ...     0.0  100.00  23.000     20.6  41.850     8.198750   \n",
      "27       4017.075  ...     0.0  100.00  23.000     20.6  41.950    25.243750   \n",
      "28       4051.300  ...     0.0   99.65  23.000     20.6  41.700    36.750000   \n",
      "...           ...  ...     ...     ...     ...      ...     ...          ...   \n",
      "1086231  3586.175  ...     1.0   50.00  38.175     17.6  93.000    14.498750   \n",
      "1086232  3578.575  ...     1.0   50.00  38.025     17.6  93.000    20.479375   \n",
      "1086233  3621.850  ...     1.0   50.00  38.100     17.6  93.000    13.916875   \n",
      "1086234  3618.125  ...     1.0   50.00  38.550     17.6  93.000     7.078750   \n",
      "1086235  3619.850  ...     1.0   50.00  38.250     17.6  93.000     2.660000   \n",
      "\n",
      "         NetWeight  SpeedChange   MotorJoules   H2Weight  \n",
      "24           900.0     3.176250  1.242087e+05   6650.675  \n",
      "25           800.0     7.131250  3.329994e+05   6648.700  \n",
      "26           900.0    -9.183125  1.337320e+05   6648.725  \n",
      "27          1100.0    17.045000  1.002176e+06   6652.050  \n",
      "28           900.0    11.506250  7.163605e+05   6647.075  \n",
      "...            ...          ...           ...        ...  \n",
      "1086231      500.0     5.941250  3.197074e+05  14867.525  \n",
      "1086232      300.0     5.980625  3.829604e+05  14868.250  \n",
      "1086233      200.0    -6.562500 -1.593112e+05  14866.475  \n",
      "1086234      100.0    -6.838125  6.348650e+04  14861.075  \n",
      "1086235      100.0    -4.418750  2.100522e+04  14864.775  \n",
      "\n",
      "[309857 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#DROP FEATURES NOT NEEDED\n",
    "\n",
    "\n",
    "# Columns to keep\n",
    "columns_to_keep = [ 'datetime','StopOnOff', \n",
    " 'ThrottlePerc', \n",
    " 'CompOnOff', \n",
    " 'TotalFCPower', \n",
    " 'FC1AirFlow', \n",
    " 'CompPower', \n",
    " 'FC3Volt', \n",
    " 'BatTotalVoltage', \n",
    " 'BatMinV', \n",
    " 'HVACDraw', \n",
    " 'BrakePerc', \n",
    " 'Signal', \n",
    " 'BatSOC', \n",
    " 'H2Temp', \n",
    " 'AirTemp', \n",
    " 'H2Perc', \n",
    " 'ActualSpeed', \n",
    " 'NetWeight', \n",
    " 'SpeedChange', \n",
    " 'MotorJoules','H2Weight'  \n",
    "]\n",
    "\n",
    "# Keep only the specified columns using .filter\n",
    "df = df.filter(items=columns_to_keep)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Stopping execution of  DF IMPORT AND DATA PREPARATION.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Stopping execution of  DF IMPORT AND DATA PREPARATION.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joelva/.pyenv/versions/3.11.5/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3556: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "raise SystemExit(\"Stopping execution of  DF IMPORT AND DATA PREPARATION.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END OF DF IMPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#APPLY MODEL TO MAKE PREDITCITON BASED ON OPERATIONAL CHARACTERISTCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This PolynomialFeatures instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m end_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022-09-30\u001b[39m\u001b[38;5;124m'\u001b[39m    \u001b[38;5;66;03m# Change as needed\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Apply the model to the original filtered data\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m original_predictions, original_data \u001b[38;5;241m=\u001b[39m \u001b[43mapply_model_to_filtered_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Feature adjustments in percentage\u001b[39;00m\n\u001b[1;32m     84\u001b[0m adjustment_percentages \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m#Operational features\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# 'StopOnOff': 0, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m  \u001b[38;5;66;03m#'H2Perc':0 \u001b[39;00m\n\u001b[1;32m    106\u001b[0m }\n",
      "Cell \u001b[0;32mIn[12], line 60\u001b[0m, in \u001b[0;36mapply_model_to_filtered_data\u001b[0;34m(df, start_date, end_date)\u001b[0m\n\u001b[1;32m     57\u001b[0m new_data \u001b[38;5;241m=\u001b[39m new_data[features]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Generate polynomial features using the previously fitted polynomial transformer\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m new_data_poly \u001b[38;5;241m=\u001b[39m \u001b[43mpoly_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Transform new data to polynomial features\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Standardize the polynomial features using the previously fitted scaler\u001b[39;00m\n\u001b[1;32m     63\u001b[0m new_data_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(new_data_poly)  \u001b[38;5;66;03m# Scale the polynomial features\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/sklearn/preprocessing/_polynomial.py:430\u001b[0m, in \u001b[0;36mPolynomialFeatures.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform data to polynomial features.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m        `csr_matrix`.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    433\u001b[0m         X, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    436\u001b[0m     n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/sklearn/utils/validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This PolynomialFeatures instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "#Run model for different settings in Operational Characteristics\n",
    "\n",
    "import joblib  # For loading models\n",
    "\n",
    "\n",
    "# Load the saved model, scaler, and polynomial transformer\n",
    "model = joblib.load('polynomial_regression_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "poly_transformer = joblib.load('poly_transformer.pkl')\n",
    "\n",
    "df1=df\n",
    "# Assuming 'df1' is your DataFrame and it contains a 'datetime' column for date filtering\n",
    "# Convert 'datetime' column to datetime type if it's not already\n",
    "df1['datetime'] = pd.to_datetime(df1['datetime'])\n",
    "\n",
    "# Function to filter data by date range\n",
    "def filter_by_date(df, start_date, end_date):\n",
    "    mask = (df['datetime'] >= start_date) & (df['datetime'] <= end_date)\n",
    "    return df[mask]\n",
    "\n",
    "# Function to apply the model to filtered data\n",
    "def apply_model_to_filtered_data(df, start_date, end_date):\n",
    "    # Filter the dataset based on the specified date range\n",
    "    filtered_df = filter_by_date(df, start_date, end_date)\n",
    "\n",
    "    # Use all columns except 'datetime' and 'MotorJoules' as features\n",
    "    features = [ 'StopOnOff', \n",
    " 'ThrottlePerc', \n",
    " 'CompOnOff', \n",
    " 'TotalFCPower', \n",
    " 'FC1AirFlow', \n",
    " 'CompPower', \n",
    " 'FC3Volt', \n",
    " 'BatTotalVoltage', \n",
    " 'BatMinV', \n",
    " 'HVACDraw', \n",
    " 'BrakePerc', \n",
    " 'Signal', \n",
    " 'BatSOC', \n",
    " 'H2Temp', \n",
    " 'AirTemp', \n",
    " 'H2Perc', \n",
    " 'ActualSpeed', \n",
    " 'NetWeight', \n",
    " 'SpeedChange', \n",
    "]\n",
    "\n",
    "    # Drop the 'datetime' and 'MotorJoules' columns as they are not used for prediction\n",
    "    new_data = filtered_df.drop(columns=['datetime', 'MotorJoules'])\n",
    "\n",
    "    # Ensure the new data has the correct feature columns\n",
    "    missing_features = set(features) - set(new_data.columns)\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"New data is missing the following required features: {missing_features}\")\n",
    "\n",
    "    # Reorder new_data columns to match the expected order\n",
    "    new_data = new_data[features]\n",
    "\n",
    "    # Generate polynomial features using the previously fitted polynomial transformer\n",
    "    new_data_poly = poly_transformer.transform(new_data)  # Transform new data to polynomial features\n",
    "\n",
    "    # Standardize the polynomial features using the previously fitted scaler\n",
    "    new_data_scaled = scaler.transform(new_data_poly)  # Scale the polynomial features\n",
    "\n",
    "    # Make predictions on the new data\n",
    "    new_predictions = model.predict(new_data_scaled)\n",
    "\n",
    "    return new_predictions, new_data\n",
    "\n",
    "# Function to adjust a feature by a percentage\n",
    "def adjust_feature(df, feature, percentage):\n",
    "    adjusted_df = df.copy()\n",
    "    adjusted_df[feature] *= (1 + percentage / 100.0)\n",
    "    return adjusted_df\n",
    "\n",
    "# Specify the date range for filtering\n",
    "start_date = '2022-09-01'  # Change as needed\n",
    "end_date = '2022-09-30'    # Change as needed\n",
    "\n",
    "# Apply the model to the original filtered data\n",
    "original_predictions, original_data = apply_model_to_filtered_data(df1, start_date, end_date)\n",
    "\n",
    "# Feature adjustments in percentage\n",
    "adjustment_percentages = {\n",
    "#Operational features\n",
    "    # 'StopOnOff': 0, \n",
    " #'CompOnOff': 0, \n",
    "  # 'Signal': 0, # Do not ues\n",
    " #'BatSOC': 0, # Example: increase by 10%\n",
    " #'H2Temp': 0, # Example: increase by 10%\n",
    " #'NetWeight': 00, # Example: increase by 10%\n",
    " #'SpeedChange': -10, # Example: increase by 10%\n",
    " 'ActualSpeed': -10,   # Example: increase by 10%\n",
    " 'ThrottlePerc': -10,  # Example: increase by 10%\n",
    " 'BrakePerc': -10,     # Example: increase by 10%\n",
    " 'AirTemp': 0,      # Example: increase by 10%\n",
    " #Technical features\n",
    "#'TotalFCPower':0, \n",
    " #'FC1AirFlow':0, \n",
    " #'CompPower':0, \n",
    " #'FC3Volt':0, \n",
    " #'BatTotalVoltage':0, \n",
    " #'BatMinV':0, \n",
    " #'HVACDraw':0, \n",
    " #'H2Perc':0 \n",
    "}\n",
    "\n",
    "# Store the sums of predictions for each adjusted feature\n",
    "adjusted_sums = {}\n",
    "\n",
    "# Apply adjustments to each feature and predict\n",
    "for feature, percentage in adjustment_percentages.items():\n",
    "    adjusted_data = adjust_feature(original_data, feature, percentage)\n",
    "    adjusted_data_poly = poly_transformer.transform(adjusted_data)\n",
    "    adjusted_data_scaled = scaler.transform(adjusted_data_poly)\n",
    "    adjusted_predictions = model.predict(adjusted_data_scaled)\n",
    "    adjusted_sum = np.sum(adjusted_predictions)\n",
    "    adjusted_sums[feature] = adjusted_sum\n",
    "\n",
    "# Sum of original predictions\n",
    "original_sum = np.sum(original_predictions)\n",
    "\n",
    "# Calculate total effect of all adjustments (sequentially applying all adjustments)\n",
    "total_adjusted_data = original_data.copy()\n",
    "for feature, percentage in adjustment_percentages.items():\n",
    "    total_adjusted_data = adjust_feature(total_adjusted_data, feature, percentage)\n",
    "\n",
    "total_adjusted_data_poly = poly_transformer.transform(total_adjusted_data)\n",
    "total_adjusted_data_scaled = scaler.transform(total_adjusted_data_poly)\n",
    "total_adjusted_predictions = model.predict(total_adjusted_data_scaled)\n",
    "total_adjusted_sum = np.sum(total_adjusted_predictions)\n",
    "\n",
    "# Determine colors for individual feature bars based on the rule (green if lower, red if higher)\n",
    "colors = []\n",
    "for feature in adjustment_percentages:\n",
    "    if adjusted_sums[feature] < original_sum:\n",
    "        colors.append('green')\n",
    "    elif adjusted_sums[feature] > original_sum:\n",
    "        colors.append('red')\n",
    "    else:\n",
    "        colors.append('grey')\n",
    "\n",
    "# Add the total effect bar color\n",
    "total_color = 'green' if total_adjusted_sum < original_sum else 'red' if total_adjusted_sum > original_sum else 'grey'\n",
    "\n",
    "# Plot the bar plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Original and individual feature adjustments\n",
    "bars = plt.bar(\n",
    "    ['Original'] + list(adjusted_sums.keys()) + ['Total Effect'],\n",
    "    [original_sum] + list(adjusted_sums.values()) + [total_adjusted_sum],\n",
    "    color=['blue'] + colors + [total_color]\n",
    ")\n",
    "\n",
    "# Add percentage difference text to bars\n",
    "for i, bar in enumerate(bars):\n",
    "    yval = bar.get_height()\n",
    "    if i == 0:  # Original bar\n",
    "        text = f'{yval:.2f}'\n",
    "    else:\n",
    "        difference = ((yval - original_sum) / original_sum) * 100\n",
    "        text = f'{yval:.2f}\\n({difference:.2f}%)'\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, text, ha='center', va='bottom' if yval < 0 else 'top', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Sum of MotorJoules')\n",
    "plt.title(f'Comparison of Sum of MotorJoules Predictions with Adjusted Features\\nDate Range: {start_date} to {end_date}')\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the sums for verification\n",
    "print(f\"Original Sum of MotorJoules: {original_sum:.2f}\")\n",
    "for feature, adjusted_sum in adjusted_sums.items():\n",
    "    print(f\"Adjusted Sum of MotorJoules with {adjustment_percentages[feature]}% {feature}: {adjusted_sum:.2f}\")\n",
    "\n",
    "print(f\"Total Adjusted Sum of MotorJoules: {total_adjusted_sum:.2f}\")\n",
    "\n",
    "# Calculate and print the change in kilograms of hydrogen\n",
    "# Calculate and print the change in kilograms of hydrogen\n",
    "change_in_hydrogen_kg = (original_sum - total_adjusted_sum) /(66670 * 1000) # 1 J / 66670 J/g = 0.000015 grams\n",
    "print(f\"Change in Kg of Hydrogen based on Operational Characteristics: {change_in_hydrogen_kg:.2f} kg\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Main",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
